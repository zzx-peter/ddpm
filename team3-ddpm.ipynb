{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import base64\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "我们定义了一个自定义数据集类 `NoisyMNISTDatasetBinary`，用于加载二进制数据（`.npz` 文件）。\n",
    "\n",
    "- 对于训练集，返回噪声图像和原始图像对。\n",
    "- 对于测试集，仅返回噪声图像。\n",
    "\n",
    "数据会被归一化到 [0, 1] 范围并转换为 PyTorch 张量。我们还将训练集划分为训练子集和验证子集（80% 训练，20% 验证），以便在训练过程中评估模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyMNISTDatasetBinary(Dataset):\n",
    "    def __init__(self, root_dir, train):\n",
    "        if train:\n",
    "            npz_file = os.path.join(root_dir, \"train.npz\")\n",
    "        else:\n",
    "            npz_file = os.path.join(root_dir, \"test.npz\")\n",
    "        data = np.load(npz_file)\n",
    "        self.noise = data['noise']      # shape: (N, H, W)\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.origin = data['origin']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.noise.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noise = torch.from_numpy(self.noise[idx]).float().unsqueeze(0) / 255.0\n",
    "        if not self.train:\n",
    "            return noise\n",
    "        origin = torch.from_numpy(self.origin[idx]).float().unsqueeze(0) / 255.0\n",
    "        return noise, origin\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = NoisyMNISTDatasetBinary(\".\", True)\n",
    "test_dataset = NoisyMNISTDatasetBinary(\".\", False)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 设置批量大小\n",
    "batch_size = 128\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据示例\n",
    "\n",
    "以下代码展示训练集中的前 8 个样本，比较原始图像和噪声图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练数据\n",
    "dataiter = iter(train_loader)\n",
    "noisy, original = next(dataiter)\n",
    "\n",
    "num_examples = min(8, len(noisy))\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# 第一行：原始图像\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, i + 1)\n",
    "    plt.imshow(original[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Original', fontsize=14, rotation=90, labelpad=20)\n",
    "\n",
    "# 第二行：噪声图像\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "    plt.imshow(noisy[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Noisy', fontsize=14, rotation=90, labelpad=20)\n",
    "\n",
    "plt.suptitle(f\"Training Examples: Original vs Noisy (First {num_examples} Samples)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义\n",
    "\n",
    "我们使用扩散模型（DDPM）来实现图像去噪。模型包括以下部分：\n",
    "\n",
    "- `SinusoidalPosEmb`：为时间步长生成正弦位置嵌入，用于条件化模型。\n",
    "- `DenoiseUNet`：一个基于 U-Net 的去噪模型，接受噪声图像和时间步长作为输入，预测噪声分量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half = self.dim // 2\n",
    "        emb = math.log(10000) / (half - 1)\n",
    "        emb = torch.exp(torch.arange(half, device=t.device) * -emb)\n",
    "        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        return emb\n",
    "\n",
    "class DenoiseUNet(nn.Module):\n",
    "    def __init__(self, time_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_dim),\n",
    "            nn.Linear(time_dim, time_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim * 4, 64)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv_out = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_mlp(t.to(x.device)).unsqueeze(-1).unsqueeze(-1)\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h) + t_emb)\n",
    "        h = F.relu(self.conv3(h))\n",
    "        return self.conv_out(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "\n",
    "我们定义了两个函数来计算批量图像的 PSNR 和 SSIM 指标，用于评估模型在验证集上的去噪性能。这些函数使用 `skimage.metrics` 库，与 `team3-template-dncnn(1).ipynb` 中的方法一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_psnr(preds, targets):\n",
    "    psnr = []\n",
    "    for p, t in zip(preds, targets):\n",
    "        p_img = p.cpu().numpy().squeeze()\n",
    "        t_img = t.cpu().numpy().squeeze()\n",
    "        psnr.append(compare_psnr(t_img, p_img, data_range=1.0))\n",
    "    return np.mean(psnr)\n",
    "\n",
    "def batch_ssim(preds, targets):\n",
    "    ssim = []\n",
    "    for p, t in zip(preds, targets):\n",
    "        p_img = p.cpu().numpy().squeeze()\n",
    "        t_img = t.cpu().numpy().squeeze()\n",
    "        ssim.append(compare_ssim(t_img, p_img, data_range=1.0))\n",
    "    return np.mean(ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "我们使用扩散模型的训练流程，通过逐步添加噪声并训练模型预测噪声分量。训练参数包括：\n",
    "\n",
    "- 扩散步数 `T = 50`\n",
    "- 噪声调度参数 `betas` 从 1e-4 到 0.02\n",
    "- 使用 Adam 优化器，学习率为 1e-3\n",
    "- 训练 5 个 epoch\n",
    "\n",
    "在每个 epoch 结束后，我们在验证集上评估模型，计算平均 PSNR 和 SSIM 指标，以监控去噪性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型和优化器\n",
    "model = DenoiseUNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 设置扩散参数\n",
    "T = 50\n",
    "betas = torch.linspace(1e-4, 0.02, T).to(device)\n",
    "alphas = 1 - betas\n",
    "alpha_bar = torch.cumprod(alphas, dim=0)\n",
    "sqrt_alpha_bar = torch.sqrt(alpha_bar)\n",
    "sqrt_one_minus_alpha_bar = torch.sqrt(1 - alpha_bar)\n",
    "\n",
    "# 验证函数\n",
    "def validate(model, val_loader, alpha_bar, t_step=20):\n",
    "    model.eval()\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    with torch.no_grad():\n",
    "        for _, clean in tqdm(val_loader, desc=\"Validation\"):\n",
    "            clean = clean.to(device)\n",
    "            B = clean.size(0)\n",
    "            t = torch.full((B,), t_step, device=device, dtype=torch.long)\n",
    "            noise = torch.randn_like(clean)\n",
    "            sqrt_ab = torch.sqrt(alpha_bar[t]).view(-1, 1, 1, 1)\n",
    "            sqrt_1_ab = torch.sqrt(1 - alpha_bar[t]).view(-1, 1, 1, 1)\n",
    "            x_noisy = sqrt_ab * clean + sqrt_1_ab * noise\n",
    "            pred_noise = model(x_noisy, t)\n",
    "            x_denoised = (x_noisy - sqrt_1_ab * pred_noise) / sqrt_ab\n",
    "            x_denoised = x_denoised.clamp(0, 1)\n",
    "            psnr = batch_psnr(x_denoised, clean)\n",
    "            ssim = batch_ssim(x_denoised, clean)\n",
    "            psnr_list.append(psnr)\n",
    "            ssim_list.append(ssim)\n",
    "    model.train()\n",
    "    return np.mean(psnr_list), np.mean(ssim_list)\n",
    "\n",
    "# 训练循环\n",
    "model.train()\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_psnrs = []\n",
    "val_ssims = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for noisy, clean in progress_bar:\n",
    "        clean = clean.to(device)\n",
    "        B = clean.size(0)\n",
    "        t = torch.randint(0, T, (B,), device=device)\n",
    "        noise = torch.randn_like(clean)\n",
    "        sqrt_ab = sqrt_alpha_bar[t].view(-1, 1, 1, 1)\n",
    "        sqrt_1_ab = sqrt_one_minus_alpha_bar[t].view(-1, 1, 1, 1)\n",
    "        x_t = sqrt_ab * clean + sqrt_1_ab * noise\n",
    "        pred = model(x_t, t)\n",
    "        loss = F.mse_loss(pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss={avg_loss:.4f}\")\n",
    "\n",
    "    # 验证\n",
    "    val_psnr, val_ssim = validate(model, val_loader, alpha_bar)\n",
    "    val_psnrs.append(val_psnr)\n",
    "    val_ssims.append(val_ssim)\n",
    "    print(f\"Validation PSNR: {val_psnr:.2f}, SSIM: {val_ssim:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"ddpm_denoise_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理与提交\n",
    "\n",
    "我们使用训练好的模型对测试集进行去噪，并将结果保存为提交所需的 CSV 文件。去噪过程在固定时间步长 `t=20` 进行，假设测试集的噪声图像对应于此时间步长的噪声水平。输出图像被转换为 base64 编码的 PNG 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将张量转换为 base64 编码的 PNG\n",
    "def tensor_to_base64(tensor):\n",
    "    tensor = tensor.squeeze().cpu().numpy()\n",
    "    tensor = (tensor * 255).astype(np.uint8)\n",
    "    img = Image.fromarray(tensor, mode='L')\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "# 去噪函数\n",
    "def denoise(model, data, alpha_bar, t_step=20):\n",
    "    model.eval()\n",
    "    t = torch.full((data.size(0),), t_step, device=device, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        pred_noise = model(data, t)\n",
    "    sqrt_ab = torch.sqrt(alpha_bar[t]).view(-1, 1, 1, 1)\n",
    "    sqrt_1_ab = torch.sqrt(1 - alpha_bar[t]).view(-1, 1, 1, 1)\n",
    "    x_denoised = (data - sqrt_1_ab * pred_noise) / sqrt_ab\n",
    "    x_denoised = x_denoised.clamp(0, 1)\n",
    "    return x_denoised\n",
    "\n",
    "# 推理并生成提交文件\n",
    "model.eval()\n",
    "submission = []\n",
    "example_noisy = []\n",
    "example_output = []\n",
    "\n",
    "for i, noisy in enumerate(tqdm(test_loader, desc=\"Inference\")):\n",
    "    noisy = noisy.to(device)\n",
    "    denoised = denoise(model, noisy, alpha_bar)\n",
    "    for j in range(denoised.size(0)):\n",
    "        img_base64 = tensor_to_base64(denoised[j])\n",
    "        submission.append({'id': i * batch_size + j, 'image': img_base64})\n",
    "    if i == 0:  # 保存第一批次用于可视化\n",
    "        example_noisy.append(noisy[:8])\n",
    "        example_output.append(denoised[:8])\n",
    "\n",
    "# 保存提交文件\n",
    "submission_df = pd.DataFrame(submission)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' has been generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去噪结果可视化\n",
    "\n",
    "以下代码展示测试集中的前 8 个样本，比较噪声输入和去噪输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化去噪结果\n",
    "num_examples = min(8, len(example_noisy[0]))\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# 第一行：噪声图像\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, i + 1)\n",
    "    plt.imshow(example_noisy[0][i][0].cpu(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Noisy Input', fontsize=14, rotation=90, labelpad=20)\n",
    "\n",
    "# 第二行：去噪结果\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "    plt.imshow(example_output[0][i][0].cpu(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Denoised Output', fontsize=14, rotation=90, labelpad=20)\n",
    "\n",
    "plt.suptitle(f\"Denoising Results Comparison (First {num_examples} Test Examples)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果分析\n",
    "\n",
    "我们通过在验证集上计算 PSNR 和 SSIM 指标来评估模型的去噪性能。PSNR 衡量像素级别的重建质量，值越高表示去噪效果越好；SSIM 衡量图像的结构相似性，值越接近 1 表示去噪图像与原始图像越相似。可以进一步分析不同时间步长 `t` 的去噪效果，或调整模型架构以提高性能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}